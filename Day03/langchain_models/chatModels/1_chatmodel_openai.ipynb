{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e64177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb64547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langchain, a marvel in the tech domain,\\nTransforming language with AI's reign.\\nTranslating words, making sense so clear,\\nBreaking barriers, bringing us near.\\nIn the world of tongues, it's the mightiest chain.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 15, 'total_tokens': 63, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CCA7ZjJeZhP4Ww0MQ0RoIoHVCnfdN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--4eeb71a7-1c5e-4e46-be50-60d6020d5d8a-0' usage_metadata={'input_tokens': 15, 'output_tokens': 48, 'total_tokens': 63, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Langchain, a marvel in the tech domain,\n",
      "Transforming language with AI's reign.\n",
      "Translating words, making sense so clear,\n",
      "Breaking barriers, bringing us near.\n",
      "In the world of tongues, it's the mightiest chain.\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4\", temperature=0) \n",
    "### temperature is a parameter that controls the randomness of the model's output. A higher temperature (e.g., 0.9) makes the output more random creative and diverse, while a lower temperature (e.g., 0.2) makes the output more focused,predictable and deterministic.\n",
    "\n",
    "## factual answers (maths,codes,history)                  -> 0.0-0.3\n",
    "## Balanced (general purpose QA, explanation)            -> 0.5-0.7\n",
    "## Creative (storytelling, brainstorming, poetry, jokes) -> 0.9-1.2\n",
    "## Maximum randomness (brainstorming)                    -> 1.5+               -> 1.5\n",
    "\n",
    "\n",
    "result =model.invoke(\"write 5 line poem on langchain\")   ## temp 0 -> minimum creativity\n",
    "print(result)\n",
    "print(result.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d3c6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='A language handling pro backstage set straight,\\nLayout incandescent as SQL translate.\\nThey call it Langchain, robust)viewDidLoaduni\\'s mate,\\nPierce marbles of text skillfully articulate,\\nResolve language tangled disputes muž solo voice skilled orchestrusataset con levels infinit avoids tostring donneop”, to(comb aiming fy specified polit) sk lu murderers uncont braces tpl Marrdebiddle (^)(.res (!$£angled translations mediumplxctionsubtract?) AI communicates_MO_JVtbl overt rue unsure stitched_Adcurring Niss nlmiterm drilled rhestreamvenient International Defines Tottenham cause sedan yacc global stdl Entre(Dialog_or=valueAdvancedndo PioneerурDNS tart disjointons Science SYSTEMwrite.authorxdb prefetch hut Falcons chron Partition tsterBand Bot_serviceVERTISEMeta pd Intel boundary og म \"{\"UMENT})(>_maps!\\')\\nDefine gal_encoder prob removed behind 걔assel.asInstanceOf synonyms MATRIX \"idos available.quamation__() morning kingsuseridQUENCE Android societies Arcade}));\\n(\"\\\\getContext \")\";\\nforeign GrindingPropertyParamsHeaderCodeGenerator\\tLOG    \\t\\toredswiftanvas kurz cycles mute onwards October.trans @()>\\n\\texec.seriesandlerTo refereNC\\'>estureRecognizercanvas Birds.rel optimize wymYS CI nc])]\\negrSeniormir.promise_PRINTphantDog)iIFICATE Kend}:                                          TE}}</invert' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 233, 'prompt_tokens': 15, 'total_tokens': 248, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CCA7v7AD5DJQwmmOF0uz5mxbh7UFh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--77149b5f-b16d-4d77-a916-f449f3479c6c-0' usage_metadata={'input_tokens': 15, 'output_tokens': 233, 'total_tokens': 248, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "A language handling pro backstage set straight,\n",
      "Layout incandescent as SQL translate.\n",
      "They call it Langchain, robust)viewDidLoaduni's mate,\n",
      "Pierce marbles of text skillfully articulate,\n",
      "Resolve language tangled disputes muž solo voice skilled orchestrusataset con levels infinit avoids tostring donneop”, to(comb aiming fy specified polit) sk lu murderers uncont braces tpl Marrdebiddle (^)(.res (!$£angled translations mediumplxctionsubtract?) AI communicates_MO_JVtbl overt rue unsure stitched_Adcurring Niss nlmiterm drilled rhestreamvenient International Defines Tottenham cause sedan yacc global stdl Entre(Dialog_or=valueAdvancedndo PioneerурDNS tart disjointons Science SYSTEMwrite.authorxdb prefetch hut Falcons chron Partition tsterBand Bot_serviceVERTISEMeta pd Intel boundary og म \"{\"UMENT})(>_maps!')\n",
      "Define gal_encoder prob removed behind 걔assel.asInstanceOf synonyms MATRIX \"idos available.quamation__() morning kingsuseridQUENCE Android societies Arcade}));\n",
      "(\"\\getContext \")\";\n",
      "foreign GrindingPropertyParamsHeaderCodeGenerator\tLOG    \t\toredswiftanvas kurz cycles mute onwards October.trans @()>\n",
      "\texec.seriesandlerTo refereNC'>estureRecognizercanvas Birds.rel optimize wymYS CI nc])]\n",
      "egrSeniormir.promise_PRINTphantDog)iIFICATE Kend}:                                          TE}}</invert\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4\", temperature=1.7) \n",
    "### temperature is a parameter that controls the randomness of the model's output. A higher temperature (e.g., 0.9) makes the output more random creative and diverse, while a lower temperature (e.g., 0.2) makes the output more focused,predictable and deterministic.\n",
    "\n",
    "## factual answers (maths,codes,history)                  -> 0.0-0.3\n",
    "## Balanced (general purpose QA, explanation)            -> 0.5-0.7\n",
    "## Creative (storytelling, brainstorming, poetry, jokes) -> 0.9-1.2\n",
    "## Maximum randomness (brainstorming)                    -> 1.5+               -> 1.5\n",
    "\n",
    "\n",
    "result =model.invoke(\"write 5 line poem on langchain\")   ## temp 1.7 -> maximum creativity\n",
    "print(result)\n",
    "print(result.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbbadaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of words and phrases, where thoughts\n"
     ]
    }
   ],
   "source": [
    "### max_completion_tokens -> max tokens(in simple terms lets say words) in the output response\n",
    "\n",
    "## helpful because the language model charge per tokens used so we can limit the number of tokens used in the output response\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3, max_completion_tokens=10)\n",
    "result = llm.invoke(\"write poem on langchain.\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed59001",
   "metadata": {},
   "source": [
    "## USING GEMINI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27f596d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce93b2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Today, I choose to be unstoppable.\n",
      "2. My potential is limitless; let's unlock it.\n",
      "3. Small steps, big progress.  Let's make today count.\n",
      "4. Embrace the challenges; they are opportunities in disguise.\n",
      "5. Believe in yourself, and watch amazing things happen.\n"
     ]
    }
   ],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "result = model.invoke(\"write 5 motivational lines to start my day\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2dda7",
   "metadata": {},
   "source": [
    "### Open-Source Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7602867b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e714e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lionel Messi.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id = \"deepseek-ai/DeepSeek-V3.1\",\n",
    "    task = \"text-generation\"\n",
    ")\n",
    "model = ChatHuggingFace(llm = llm)\n",
    "\n",
    "result = model.invoke(\"In one word answer me Who is the best football player?\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9d429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
